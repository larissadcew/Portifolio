[![.github/workflows/ci.yaml](https://github.com/pages-themes/minimal/actions/workflows/ci.yaml/badge.svg)](https://github.com/pages-themes/minimal/actions/workflows/ci.yaml) [![Gem Version](https://badge.fury.io/rb/jekyll-theme-minimal.svg)](https://badge.fury.io/rb/jekyll-theme-minimal)

*Minimal is a Jekyll theme for GitHub Pages. You can [preview the theme to see what it looks like](http://pages-themes.github.io/minimal), or even [use it today](#usage).*

![Thumbnail of Minimal](thumbnail.png)

<img src="Fotolinkedin.png" alt="Thumbnail of Minimal" width="200" style="float: left; margin-right: 20px;" />

## 👋🏼 Hello there, I’m Larissa!


👨🏻‍💻 I’m a final year graduate student at the TU Berlin

🔬 My research interests are in bridging vision and language modalities and Self-Supervised Learning!

📽️ I am also interested in assisting others on their path in the world of Machine Learning and academia.
## Selected Experience

🤖 Open Source Contributions
I have experience contributing to Arena Bench a large open-source project for robotic obstacle avoidance using Deep Reinforcement Learning.

Moreover, I have published a respective paper at the IROS conference and in the Robotics and Automation Letters (RA-L) journal.

### 📜 Reimplementing and Reproducing Papers

I have experience with independent research. I have implemented the Reward Constrained Policy Optimization paper into stable-baselines3 PPO and reproduced the original results by running and tracking experiments.

To accompany this work, I have submitted a blog post to the ICLR Blogposts Track communicating the paper’s theory and my results.
