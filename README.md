# Larissa Barcellos Ferreira

<img src="Fotolinkedin.png" alt="Thumbnail of Minimal" width="200" style="margin-right: 20px;" />

[![.github/workflows/ci.yaml](https://github.com/pages-themes/minimal/actions/workflows/ci.yaml/badge.svg)](https://github.com/pages-themes/minimal/actions/workflows/ci.yaml) [![Gem Version](https://badge.fury.io/rb/jekyll-theme-minimal.svg)](https://badge.fury.io/rb/jekyll-theme-minimal)

*Minimal is a Jekyll theme for GitHub Pages. You can [preview the theme to see what it looks like](http://pages-themes.github.io/minimal), or even [use it today](#usage).*

## ğŸ‘‹ğŸ¼ Hello there, I'm Larissa!(WEB)


ğŸ‘¨ğŸ»â€ğŸ’» I have completed my studies at Harvard university.

ğŸ”¬ My research interests are in bridging vision and language modalities and Self-Supervised Learning!

ğŸ“½ï¸ I am also interested in assisting others on their path in the world of Machine Learning.
## Selected Experience

ğŸ¤– Open Source Contributions
I have experience contributing to mor the 50+projects a large open-source project for robotic obstacle avoidance using Deep Reinforcement Learning.

Moreover, I have published a respective paper at the IROS conference and in the Robotics and Automation Letters (RA-L) journal.

### ğŸ“œ Reimplementing and Reproducing Papers

I have experience with independent research. I have implemented the Reward Constrained Policy Optimization paper into stable-baselines3 PPO and reproduced the original results by running and tracking experiments.

To accompany this work, I have submitted a blog post to the ICLR Blogposts Track communicating the paperâ€™s theory and my results.
